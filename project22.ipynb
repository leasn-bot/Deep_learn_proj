{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load and sorting\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define a path to the directory containing your images\n",
    "data_dir = Path(\"path/to/your/images\")\n",
    "\n",
    "# Use regex to capture the sample, z-position, and channel\n",
    "pattern = re.compile(r\"s(\\d{3})z(\\d{2})c(\\d)_ORG\\.tiff$\")\n",
    "\n",
    "# List to hold file information\n",
    "file_data = []\n",
    "\n",
    "# Go through each file in the directory\n",
    "for file_path in data_dir.glob(\"*.tiff\"):\n",
    "    filename = file_path.name\n",
    "    match = pattern.search(filename)\n",
    "    if match:\n",
    "        # Extract sample, z-position, and channel\n",
    "        sample = int(match.group(1))\n",
    "        z_position = int(match.group(2))\n",
    "        channel = int(match.group(3))\n",
    "        \n",
    "        # Append the file data to the list\n",
    "        file_data.append({\n",
    "            \"file_path\": file_path,\n",
    "            \"filename\": filename,\n",
    "            \"sample\": sample,\n",
    "            \"z_position\": z_position,\n",
    "            \"channel\": channel\n",
    "        })\n",
    "\n",
    "# Convert the list into a DataFrame for easy sorting\n",
    "df = pd.DataFrame(file_data)\n",
    "\n",
    "# Sort by sample, z-position, and channel\n",
    "df_sorted = df.sort_values(by=[\"sample\", \"z_position\", \"channel\"]).reset_index(drop=True)\n",
    "\n",
    "# Preview sorted DataFrame\n",
    "print(df_sorted)\n",
    "\n",
    "# Optional: Save files into a new directory structure for easier access\n",
    "sorted_dir = data_dir / \"sorted_images\"\n",
    "sorted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for _, row in df_sorted.iterrows():\n",
    "    # Define new path based on sample and z-position\n",
    "    sample_dir = sorted_dir / f\"sample_{row['sample']}\"\n",
    "    z_dir = sample_dir / f\"z_{row['z_position']}\"\n",
    "    z_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy the file to the new location\n",
    "    target_path = z_dir / row['filename']\n",
    "    if not target_path.exists():\n",
    "        os.link(row['file_path'], target_path)  # or use shutil.copy for deep copy\n",
    "\n",
    "print(\"Files organized successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(11, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# simple CNN model\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PrintSize(nn.Module):\n",
    "    \"\"\"Utility module to print current shape of a Tensor in Sequential, only at the first pass.\"\"\"\n",
    "    \n",
    "    first = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.first:\n",
    "            print(f\"Size: {x.size()}\")\n",
    "            self.first = False\n",
    "        return x\n",
    "\n",
    "# create model as a class using pytorch\n",
    "# 11 channel input, one channel output\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #5x5 square convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=11, out_channels=32, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=1)\n",
    "\n",
    "        #reLU activation\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        #max pooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #convolution 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        #convolution 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        #convolution 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #flatten\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "\n",
    "        #fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "        # # Max pooling over a (2, 2) window\n",
    "        # x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # # If the size is a square you can only specify a single number\n",
    "        # x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # x = x.view(-1, self.num_flat_features(x))\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        # return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "model = Net()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loss Function and Optimizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test network before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits:\n",
      "[[ 0.03886781 -0.02025883 -0.00691133 ...  0.04848625  0.00193986\n",
      "  -0.00317327]\n",
      " [-0.16059351 -0.06139738 -0.00373689 ...  0.00537689  0.02744661\n",
      "   0.12507975]\n",
      " [-0.02228721 -0.04071133  0.08149298 ... -0.02612013 -0.07958535\n",
      "   0.07468948]\n",
      " ...\n",
      " [-0.25064653 -0.06748635  0.00727729 ... -0.04061291  0.044673\n",
      "   0.0860717 ]\n",
      " [-0.12622061 -0.11766759  0.08000813 ... -0.03136643 -0.03241026\n",
      "   0.11948291]\n",
      " [ 0.02717645 -0.09066263  0.01199031 ...  0.01981709 -0.05321397\n",
      "  -0.00031   ]]\n",
      "Output probabilities:\n",
      "[[0.0086699  0.00817213 0.00828194 ... 0.00875369 0.00835557 0.00831296]\n",
      " [0.00700331 0.00773363 0.00819267 ... 0.00826767 0.00845217 0.00931901]\n",
      " [0.00809448 0.00794671 0.00897967 ... 0.00806352 0.00764372 0.00891878]\n",
      " ...\n",
      " [0.00640943 0.00769777 0.00829534 ... 0.00790744 0.00861142 0.00897541]\n",
      " [0.00726263 0.00732501 0.00892602 ... 0.00798525 0.00797692 0.00928542]\n",
      " [0.0085669  0.0076146  0.00843779 ... 0.00850409 0.00790516 0.00833463]]\n"
     ]
    }
   ],
   "source": [
    "out = model(torch.randn(1, 11, 100, 100, device=device))\n",
    "\n",
    "print(f\"Output logits:\\n{out.detach().cpu().numpy()}\")\n",
    "print(f\"Output probabilities:\\n{out.softmax(1).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(11, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (relu3): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "validation_every_n = 100\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import data_utils\n",
    "\n",
    "#import sys\n",
    "#sys.path.append(os.path.join('.', '..')) # Allow us to import shared custom\n",
    "#                                         # libraries, like utils.py\n",
    "\n",
    "path = 'data/'\n",
    "\n",
    "image_paths = glob.glob(path+'images/*.jpg')\n",
    "print(\"Total Observations:\\t\", len(image_paths))\n",
    "\n",
    "# now loading the train.csv to find features for each training point\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "train_images = [path+'images/{}.jpg'.format(i) for i in train.id.values]\n",
    "\n",
    "# now loading the test.csv\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "# First we find an example of each species in order to visualize it\n",
    "species = np.array(sorted(train.species.unique()))\n",
    "species_examples = [np.random.choice(train[train.species == s].id.values) for s in species]\n",
    "\n",
    "# Then we gather its index in our list of images in order to find the correct image\n",
    "indexes = [image_paths.index(path + 'images/{}.jpg'.format(i)) for i in species_examples]\n",
    "\n",
    "# Display the first image\n",
    "plt.figure(figsize=(8, 8))\n",
    "image = imread(image_paths[indexes[0]], as_gray=True)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"%s\" % (species[0]))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Now plot 1 image from each category\n",
    "\n",
    "# Number of species\n",
    "num_species = len(species)\n",
    "\n",
    "# Rows and columns for the subplot grid\n",
    "rows = int(np.ceil(num_species / 10))\n",
    "cols = min(10, num_species)  # Ensure at least 10 columns\n",
    "\n",
    "# Figure for the subplots\n",
    "plt.figure(figsize=(30, rows * 3))\n",
    "\n",
    "# Extracting one image of each species\n",
    "for i, (species_name, image_idx) in enumerate(zip(species, indexes)):\n",
    "    image = imread(image_paths[image_idx], as_gray=True)\n",
    "    # Subplot for image\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(species_name, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course02456",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
